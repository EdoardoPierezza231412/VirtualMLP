{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true) + K.sum(y_pred)\n",
    "    dice = (2. * intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    return 1 - dice\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image from the environment...\n",
      "Image captured and saved at: textures/_plates/033_43-13-ROOT1-2023-08-08_pvd_OD01_Col0_02-Fish Eye Corrected.png\n",
      "Cropping the Petri dish from the image...\n",
      "Splitting the cropped image...\n",
      "Loading the mask segmentation model...\n",
      "Processing split 1 of 5...\n",
      "2/2 [==============================] - 4s 135ms/step\n",
      "Split 1 root tip in robot coordinates: [0.12640008880994671, 0.11075666074600354, 0.057]\n",
      "Processing split 2 of 5...\n",
      "2/2 [==============================] - 3s 113ms/step\n",
      "Split 2 root tip in robot coordinates: [0.12512122557726466, 0.09029484902309058, 0.057]\n",
      "Processing split 3 of 5...\n",
      "2/2 [==============================] - 3s 122ms/step\n",
      "Split 3 root tip in robot coordinates: [0.12261678507992894, 0.097595026642984, 0.057]\n",
      "Processing split 4 of 5...\n",
      "2/2 [==============================] - 3s 122ms/step\n",
      "Split 4 root tip in robot coordinates: [0.12112477797513321, 0.09599644760213144, 0.057]\n",
      "Processing split 5 of 5...\n",
      "2/2 [==============================] - 3s 123ms/step\n",
      "Split 5 root tip in robot coordinates: [0.13503241563055063, 0.11629840142095915, 0.057]\n",
      "Loading the RL model...\n",
      "Starting inoculation process with RL model...\n",
      "Processing root tip 1 at goal position: [0.12640008880994671, 0.11075666074600354, 0.057]\n",
      "Reset: Pipette Position [0.073  0.0895 0.1195], Goal Position [-0.08768614  0.17035805  0.17902592]\n",
      "Step 1 called with action: [-1.  1.  1.]\n",
      "Error during step execution: 'bool' object is not callable\n",
      "Finished processing root tip 1\n",
      "Processing root tip 2 at goal position: [0.12512122557726466, 0.09029484902309058, 0.057]\n",
      "Reset: Pipette Position [0.073  0.0895 0.1195], Goal Position [-0.11880466  0.13367043  0.17599443]\n",
      "Step 1 called with action: [-1.         1.         0.9616586]\n",
      "Error during step execution: 'bool' object is not callable\n",
      "Finished processing root tip 2\n",
      "Processing root tip 3 at goal position: [0.12261678507992894, 0.097595026642984, 0.057]\n",
      "Reset: Pipette Position [0.073  0.0895 0.1195], Goal Position [ 0.15118614 -0.00107637  0.2647562 ]\n",
      "Step 1 called with action: [ 1. -1.  1.]\n",
      "Error during step execution: 'bool' object is not callable\n",
      "Finished processing root tip 3\n",
      "Processing root tip 4 at goal position: [0.12112477797513321, 0.09599644760213144, 0.057]\n",
      "Reset: Pipette Position [0.073  0.0895 0.1195], Goal Position [0.02758023 0.20016961 0.24199295]\n",
      "Step 1 called with action: [-1.  1.  1.]\n",
      "Error during step execution: 'bool' object is not callable\n",
      "Finished processing root tip 4\n",
      "Processing root tip 5 at goal position: [0.13503241563055063, 0.11629840142095915, 0.057]\n",
      "Reset: Pipette Position [0.073  0.0895 0.1195], Goal Position [ 0.1991424  -0.11580253  0.26572537]\n",
      "Step 1 called with action: [ 1. -1.  1.]\n",
      "Error during step execution: 'bool' object is not callable\n",
      "Finished processing root tip 5\n",
      "Inoculation process with RL model completed.\n",
      "Closing the environment...\n",
      "Closing environment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from stable_baselines3 import PPO  # Import RL model\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from skimage.morphology import skeletonize\n",
    "from ot2_env_wrapper import OT2Env  # Custom environment wrapper\n",
    "from clearml import Task  # Import ClearML's Task\n",
    "\n",
    "\n",
    "\n",
    "def crop_petri_dish(image, patch_size):\n",
    "    \"\"\"\n",
    "    Detect and crop the Petri dish from the image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - patch_size: Tuple (height, width) to pad the cropped Petri dish.\n",
    "\n",
    "    Returns:\n",
    "    - Cropped image focused on the Petri dish.\n",
    "    - Bounding box of the Petri dish.\n",
    "    - Success flag.\n",
    "    \"\"\"\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, binary = cv2.threshold(image, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Detect the largest contour as the Petri dish\n",
    "    largest_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "    if largest_contour is None:\n",
    "        print(\"Error: No Petri dish detected.\")\n",
    "        return None, None, False\n",
    "\n",
    "    # Get the bounding box of the Petri dish\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    # Crop the image based on the bounding box\n",
    "    cropped_image = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Pad the cropped image to ensure it matches the patch size\n",
    "    padded_image = pad_image(cropped_image, patch_size)\n",
    "\n",
    "    return padded_image, (x, y, w, h), True\n",
    "\n",
    "\n",
    "def pad_image(image, patch_size):\n",
    "    \"\"\"\n",
    "    Pad the cropped image to match the required patch size.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input cropped image (numpy array).\n",
    "    - patch_size: Tuple (height, width) for padding.\n",
    "\n",
    "    Returns:\n",
    "    - Padded image.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    pad_height = (patch_size[0] - height % patch_size[0]) % patch_size[0]\n",
    "    pad_width = (patch_size[1] - width % patch_size[1]) % patch_size[1]\n",
    "    return cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "\n",
    "def split_image(image, num_parts):\n",
    "    \"\"\"\n",
    "    Split the image into equal vertical parts.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - num_parts: Number of parts to split the image into.\n",
    "\n",
    "    Returns:\n",
    "    - List of image splits.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    part_width = width // num_parts\n",
    "    return [image[:, i * part_width:(i + 1) * part_width] for i in range(num_parts)]\n",
    "\n",
    "\n",
    "def merge_images(splits, original_shape):\n",
    "    \"\"\"\n",
    "    Merge image splits back into the original shape.\n",
    "\n",
    "    Parameters:\n",
    "    - splits: List of image splits.\n",
    "    - original_shape: Tuple (height, width) of the original image.\n",
    "\n",
    "    Returns:\n",
    "    - Merged image.\n",
    "    \"\"\"\n",
    "    merged_image = np.zeros(original_shape, dtype=np.uint8)\n",
    "    part_width = original_shape[1] // len(splits)\n",
    "    for i, split in enumerate(splits):\n",
    "        merged_image[:, i * part_width:(i + 1) * part_width] = split\n",
    "    return merged_image\n",
    "\n",
    "\n",
    "def generate_mask(image, model, patch_size):\n",
    "    \"\"\"\n",
    "    Generate a binary mask from an input image using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - model: Trained Keras model.\n",
    "    - patch_size: Tuple (height, width) for patching.\n",
    "\n",
    "    Returns:\n",
    "    - mask: Predicted binary mask (numpy array).\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    # Pad the image\n",
    "    pad_height = (patch_size[0] - height % patch_size[0]) % patch_size[0]\n",
    "    pad_width = (patch_size[1] - width % patch_size[1]) % patch_size[1]\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Patch the image\n",
    "    patches = []\n",
    "    for y in range(0, padded_image.shape[0], patch_size[0]):\n",
    "        for x in range(0, padded_image.shape[1], patch_size[1]):\n",
    "            patch = padded_image[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "            patches.append(patch / 255.0)  # Normalize\n",
    "\n",
    "    patches = np.array(patches)[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "    # Predict patches\n",
    "    predicted_patches = model.predict(patches)\n",
    "    predicted_patches = (predicted_patches > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Reconstruct the mask\n",
    "    reconstructed_mask = np.zeros_like(padded_image, dtype=np.uint8)\n",
    "    idx = 0\n",
    "    for y in range(0, padded_image.shape[0], patch_size[0]):\n",
    "        for x in range(0, padded_image.shape[1], patch_size[1]):\n",
    "            reconstructed_mask[y:y + patch_size[0], x:x + patch_size[1]] = predicted_patches[idx].squeeze()\n",
    "            idx += 1\n",
    "\n",
    "    # Crop back to the original size\n",
    "    return reconstructed_mask[:height, :width]\n",
    "\n",
    "\n",
    "def detect_root_tip_with_skeletonization(mask, kernel_size=10, closing_iterations=3, min_area=400):\n",
    "    \"\"\"\n",
    "    Detect the root tip using the improved skeletonization process.\n",
    "\n",
    "    Parameters:\n",
    "    - mask: Binary mask (numpy array).\n",
    "    - kernel_size: Kernel size for morphological operations.\n",
    "    - closing_iterations: Number of iterations for morphological closing.\n",
    "    - min_area: Minimum area for connected components.\n",
    "\n",
    "    Returns:\n",
    "    - root_tip: Tuple (y_pixel, x_pixel) of the root tip.\n",
    "    \"\"\"\n",
    "    # Improve connectivity\n",
    "    improved_mask = improve_connectivity(mask, kernel_size, closing_iterations)\n",
    "\n",
    "    # Extract large connected components\n",
    "    large_components = extract_large_components(improved_mask, min_area=min_area)\n",
    "\n",
    "    # Find the longest path in the largest component\n",
    "    longest_path = None\n",
    "    max_length = 0\n",
    "\n",
    "    for label, component_mask, area, stats in large_components:\n",
    "        path, length, skeleton = find_longest_path_in_component(component_mask)\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            longest_path = path\n",
    "\n",
    "    if not longest_path:\n",
    "        raise ValueError(\"No valid root tip detected in the skeletonized mask.\")\n",
    "\n",
    "    # The root tip is the endpoint of the longest path (lowest pixel)\n",
    "    root_tip = longest_path[-1]\n",
    "    return root_tip\n",
    "\n",
    "def improve_connectivity(mask, kernel_size=5, closing_iterations=3):\n",
    "    \"\"\"\n",
    "    Improves connectivity in the binary mask by applying morphological closing.\n",
    "    \"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    improved_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=closing_iterations)\n",
    "    return improved_mask\n",
    "\n",
    "\n",
    "def skeleton_to_graph(skeleton):\n",
    "    \"\"\"Converts a skeletonized image to a graph using networkx.\"\"\"\n",
    "    G = nx.Graph()\n",
    "    skeleton_pixels = np.argwhere(skeleton > 0)\n",
    "    for y, x in skeleton_pixels:\n",
    "        G.add_node((y, x))\n",
    "        for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (-1, 1), (1, -1), (1, 1)]:\n",
    "            neighbor = (y + dy, x + dx)\n",
    "            if (neighbor[0] >= 0 and neighbor[1] >= 0 and neighbor in G.nodes):\n",
    "                G.add_edge((y, x), neighbor)\n",
    "    return G\n",
    "\n",
    "\n",
    "def find_longest_path_in_component(component_mask):\n",
    "    \"\"\"\n",
    "    Finds the longest path in a single connected component using its skeleton.\n",
    "    \"\"\"\n",
    "    skeleton = skeletonize(component_mask // 255)\n",
    "    G = skeleton_to_graph(skeleton)\n",
    "    topmost_pixel = tuple(np.argwhere(skeleton > 0).min(axis=0))\n",
    "\n",
    "    if topmost_pixel not in G.nodes:\n",
    "        skeleton_pixels = np.array(list(G.nodes))\n",
    "        distances = np.sum(np.abs(skeleton_pixels - np.array(topmost_pixel)), axis=1)\n",
    "        closest_node = tuple(skeleton_pixels[np.argmin(distances)])\n",
    "        topmost_pixel = closest_node\n",
    "\n",
    "    lengths = nx.single_source_dijkstra_path_length(G, source=topmost_pixel)\n",
    "    bottommost_pixel = max(lengths, key=lengths.get)\n",
    "    longest_path = nx.shortest_path(G, source=topmost_pixel, target=bottommost_pixel)\n",
    "    return longest_path, lengths[bottommost_pixel], skeleton\n",
    "\n",
    "\n",
    "def extract_large_components(mask, min_area=500):\n",
    "    \"\"\"\n",
    "    Extracts connected components larger than a specified area.\n",
    "    \"\"\"\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    large_components = []\n",
    "    for label in range(1, num_labels):  # Skip background\n",
    "        area = stats[label, cv2.CC_STAT_AREA]\n",
    "        if area >= min_area:\n",
    "            component_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "            component_mask[labels == label] = 255\n",
    "            large_components.append((label, component_mask, area, stats[label]))\n",
    "    return large_components\n",
    "\n",
    "def convert_pixel_to_mm(root_tip_pixel, image_height, plate_height_mm):\n",
    "    \"\"\"\n",
    "    Convert pixel coordinates to millimeters.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tip_pixel: Root tip coordinates in pixels (y_pixel, x_pixel).\n",
    "    - image_height: Height of the original image in pixels.\n",
    "    - plate_height_mm: Real-world height of the plate in millimeters.\n",
    "\n",
    "    Returns:\n",
    "    - root_tip_mm: Root tip coordinates in millimeters (x_mm, y_mm, z_mm).\n",
    "    \"\"\"\n",
    "    scale = plate_height_mm / image_height  # mm per pixel\n",
    "    y_mm = root_tip_pixel[0] * scale\n",
    "    x_mm = root_tip_pixel[1] * scale\n",
    "    return (x_mm, y_mm, 0)  \n",
    "\n",
    "\n",
    "def convert_to_robot_coordinates(root_tip_mm, plate_position_robot):\n",
    "    \"\"\"\n",
    "    Convert root tip positions in mm (relative to the plate) to robot space.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tip_mm: Root tip position in mm (x_mm, y_mm, z_mm).\n",
    "    - plate_position_robot: Position of the top-left corner of the plate in robot space [x, y, z].\n",
    "\n",
    "    Returns:\n",
    "    - root_tip_robot: Root tip position in robot space (x_robot, y_robot, z_robot).\n",
    "    \"\"\"\n",
    "    # Convert from mm to meters\n",
    "    root_tip_m = [\n",
    "        root_tip_mm[0] / 1000,\n",
    "        root_tip_mm[1] / 1000,\n",
    "        root_tip_mm[2] / 1000,\n",
    "    ]\n",
    "\n",
    "    # Add the plate position to get the robot space coordinates\n",
    "    return [\n",
    "        root_tip_m[0] + plate_position_robot[0],\n",
    "        root_tip_m[1] + plate_position_robot[1],\n",
    "        root_tip_m[2] + plate_position_robot[2],\n",
    "    ]\n",
    "\n",
    "def inoculate_with_rl(env, root_tips_robot, model_path_LR):\n",
    "    rl_model = PPO.load(model_path_LR)\n",
    "\n",
    "    for idx, root_tip in enumerate(root_tips_robot):\n",
    "        print(f\"Starting inoculation for root tip {idx + 1} at {root_tip}\")\n",
    "        done = False\n",
    "        truncated = False\n",
    "        obs, _ = env.reset()\n",
    "        env.goal_position = np.array(root_tip)\n",
    "\n",
    "        while not done and not truncated:\n",
    "            try:\n",
    "                action, _ = rl_model.predict(obs)\n",
    "                obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "                # Log the current pipette position and error\n",
    "                current_position = obs[:3]\n",
    "                xy_error = np.linalg.norm(env.goal_position[:2] - current_position[:2])\n",
    "                print(f\"Step: Current XY: {current_position[:2]}, Goal XY: {env.goal_position[:2]}, Error XY: {xy_error}\")\n",
    "\n",
    "                if done:\n",
    "                    print(f\"Goal reached successfully at position: {current_position[:2]}\")\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during RL step execution: {e}\")\n",
    "                break\n",
    "\n",
    "        print(f\"Finished processing root tip {idx + 1}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Main Workflow for RL Model with Mask Segmentation\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize environment and parameters\n",
    "    env = OT2Env(render=True)\n",
    "    \n",
    "    # Parameters\n",
    "    mask_model_path = r\"C:\\Users\\Edopi\\Desktop\\2024-25b-fai2-adsai-EdoardoPierezza231412\\datalab_tasks\\Task8\\Edoardo_231412_undet_model256px_base.h5\"  # Path to segmentation (mask) model\n",
    "    model_path_LR = r\"C:\\Users\\Edopi\\Downloads\\model (7).zip\" # Path to RL model\n",
    "    patch_size = (256, 256)\n",
    "    plate_position_robot = [0.10775, 0.088 - 0.026, 0.057]  # Adjusted plate position\n",
    "    image_height = 2816  # Original image height in pixels\n",
    "    plate_height_mm = 150  # Plate height in millimeters\n",
    "\n",
    "    try:\n",
    "        # Capture the image from the environment\n",
    "        print(\"Capturing image from the environment...\")\n",
    "        image_path = env.image()\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            raise ValueError(\"Failed to load the image. Check the image path or capture process.\")\n",
    "\n",
    "        # Crop the Petri dish from the captured image\n",
    "        print(\"Cropping the Petri dish from the image...\")\n",
    "        cropped_image, bbox, success = crop_petri_dish(image, patch_size)\n",
    "        if not success:\n",
    "            raise RuntimeError(\"Failed to detect and crop the Petri dish.\")\n",
    "\n",
    "        # Split the cropped image into parts for processing\n",
    "        print(\"Splitting the cropped image...\")\n",
    "        splits = split_image(cropped_image, num_parts=5)\n",
    "\n",
    "        # Load the mask model\n",
    "        print(\"Loading the mask segmentation model...\")\n",
    "        mask_model = load_model(mask_model_path, custom_objects={\"f1\": f1, \"dice_loss\": dice_loss})\n",
    "\n",
    "        # Initialize variables to store results\n",
    "        root_tips_mm = []\n",
    "        root_tips_robot = []\n",
    "\n",
    "        # Process each split image\n",
    "        for idx, split in enumerate(splits):\n",
    "            print(f\"Processing split {idx + 1} of {len(splits)}...\")\n",
    "\n",
    "            # Generate the mask for the current split\n",
    "            mask = generate_mask(split, mask_model, patch_size)\n",
    "\n",
    "            # Detect the root tip using skeletonization\n",
    "            root_tip_pixel = detect_root_tip_with_skeletonization(\n",
    "                mask, kernel_size=10, closing_iterations=3, min_area=400\n",
    "            )\n",
    "\n",
    "            # Convert the root tip's pixel coordinates to millimeters\n",
    "            root_tip_mm = convert_pixel_to_mm(\n",
    "                root_tip_pixel, image_height // len(splits), plate_height_mm // len(splits)\n",
    "            )\n",
    "            root_tips_mm.append(root_tip_mm)\n",
    "\n",
    "            # Convert the millimeter coordinates to robot space\n",
    "            root_tip_robot = convert_to_robot_coordinates(root_tip_mm, plate_position_robot)\n",
    "            root_tips_robot.append(root_tip_robot)\n",
    "\n",
    "            print(f\"Split {idx + 1} root tip in robot coordinates: {root_tip_robot}\")\n",
    "\n",
    "        # Load the RL model\n",
    "        print(\"Loading the RL model...\")\n",
    "        rl_model = PPO.load(model_path_LR)\n",
    "\n",
    "        print(\"Starting inoculation process with RL model...\")\n",
    "        for idx, goal_position in enumerate(root_tips_robot):\n",
    "            print(f\"Processing root tip {idx + 1} at goal position: {goal_position}\")\n",
    "            obs, _ = env.reset()  # Reset environment and get initial observation\n",
    "            env.goal_position = goal_position  # Set the goal position for the environment\n",
    "\n",
    "            # Initialize done and truncated as booleans\n",
    "            done = False\n",
    "            truncated = False\n",
    "\n",
    "            # Verify that `obs` is valid\n",
    "            assert isinstance(obs, np.ndarray), f\"Invalid observation: {obs}\"\n",
    "\n",
    "            while not done and not truncated:\n",
    "                try:\n",
    "                    # Predict the action using the RL model\n",
    "                    action, _ = rl_model.predict(obs)\n",
    "                    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "                    # Verify step outputs\n",
    "                    assert isinstance(done, bool), f\"`done` should be a bool but got {done}\"\n",
    "                    assert isinstance(truncated, bool), f\"`truncated` should be a bool but got {truncated}\"\n",
    "                    assert isinstance(obs, np.ndarray), f\"Invalid observation: {obs}\"\n",
    "\n",
    "                    # Render the environment\n",
    "                    env.render()\n",
    "\n",
    "                    # Log progress\n",
    "                    xy_error = np.linalg.norm(goal_position[:2] - obs[:2])\n",
    "                    print(f\"Current XY: {obs[:2]}, Goal XY: {goal_position[:2]}, Error XY: {xy_error}\")\n",
    "\n",
    "                    # Check if within the acceptable XY error threshold\n",
    "                    if xy_error < 0.001:\n",
    "                        print(f\"Inoculating at position {obs[:2]} (XY Accuracy Met)\")\n",
    "                        print(\"Simulating inoculum drop...\")  # Placeholder for inoculum drop action\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during step execution: {e}\")\n",
    "                    break\n",
    "\n",
    "            print(f\"Finished processing root tip {idx + 1}\")\n",
    "\n",
    "\n",
    "        print(\"Inoculation process with RL model completed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during execution: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close the environment after execution\n",
    "        print(\"Closing the environment...\")\n",
    "        env.close()\n",
    "\n",
    "\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlockB2GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
