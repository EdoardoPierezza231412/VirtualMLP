{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captured and saved at: textures/_plates/035_43-17-ROOT1-2023-08-08_mock_pH5_+Fe_Col0_04-Fish Eye Corrected.png\n",
      "Image saved at: textures/_plates/035_43-17-ROOT1-2023-08-08_mock_pH5_+Fe_Col0_04-Fish Eye Corrected.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIDController import PIDController  # Import your PID controller\n",
    "from OT2Eenv import OT2Env       # Import your environment\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = OT2Env()\n",
    "image_path = env.image()\n",
    "print(f\"Image saved at: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true) + K.sum(y_pred)\n",
    "    dice = (2. * intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    return 1 - dice\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captured and saved at: textures/_plates/030_43-2-ROOT1-2023-08-08_pvdCherry_OD001_Col0_05-Fish Eye Corrected.png\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "Step 1 called.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OT2Env' object has no attribute 'goal_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 245\u001b[0m\n\u001b[0;32m    242\u001b[0m root_tip_robot \u001b[38;5;241m=\u001b[39m convert_to_robot_coordinates(root_tip_mm, plate_position_robot)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# Use the PID controller for inoculation\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[43minoculate_with_pid\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mroot_tip_robot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 200\u001b[0m, in \u001b[0;36minoculate_with_pid\u001b[1;34m(env, root_tips_robot)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Take action\u001b[39;00m\n\u001b[0;32m    199\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([control_x, control_y, control_z], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 200\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# Check if the robot is within the acceptable error threshold\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(target_position \u001b[38;5;241m-\u001b[39m current_position) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.01\u001b[39m:  \u001b[38;5;66;03m# Example threshold\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Edopi\\Desktop\\VirtualMLP\\OT2Eenv.py:117\u001b[0m, in \u001b[0;36mOT2Env.step\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m    114\u001b[0m pipette_position \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(observation[robot_id_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipette_position\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Compute errors for each axis\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m error_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoal_position\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m pipette_position[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    118\u001b[0m error_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_position[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m pipette_position[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    119\u001b[0m error_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_position[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m pipette_position[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OT2Env' object has no attribute 'goal_position'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from PIDController import PIDController\n",
    "from OT2Eenv import OT2Env  # Updated environment class\n",
    "\n",
    "\n",
    "def crop_petri_dish(image, patch_size):\n",
    "    \"\"\"\n",
    "    Detect and crop the Petri dish from the image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - patch_size: Tuple (height, width) to pad the cropped Petri dish.\n",
    "\n",
    "    Returns:\n",
    "    - Cropped image focused on the Petri dish.\n",
    "    - Bounding box of the Petri dish.\n",
    "    - Success flag.\n",
    "    \"\"\"\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, binary = cv2.threshold(image, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Detect the largest contour as the Petri dish\n",
    "    largest_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "    if largest_contour is None:\n",
    "        print(\"Error: No Petri dish detected.\")\n",
    "        return None, None, False\n",
    "\n",
    "    # Get the bounding box of the Petri dish\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    # Crop the image based on the bounding box\n",
    "    cropped_image = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Pad the cropped image to ensure it matches the patch size\n",
    "    padded_image = pad_image(cropped_image, patch_size)\n",
    "\n",
    "    return padded_image, (x, y, w, h), True\n",
    "\n",
    "\n",
    "def pad_image(image, patch_size):\n",
    "    \"\"\"\n",
    "    Pad the cropped image to match the required patch size.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input cropped image (numpy array).\n",
    "    - patch_size: Tuple (height, width) for padding.\n",
    "\n",
    "    Returns:\n",
    "    - Padded image.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    pad_height = (patch_size[0] - height % patch_size[0]) % patch_size[0]\n",
    "    pad_width = (patch_size[1] - width % patch_size[1]) % patch_size[1]\n",
    "    return cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "def generate_mask(image, model, patch_size):\n",
    "    \"\"\"\n",
    "    Generate a binary mask from an input image using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - model: Trained Keras model.\n",
    "    - patch_size: Tuple (height, width) for patching.\n",
    "\n",
    "    Returns:\n",
    "    - mask: Predicted binary mask (numpy array).\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    # Pad the image\n",
    "    pad_height = (patch_size[0] - height % patch_size[0]) % patch_size[0]\n",
    "    pad_width = (patch_size[1] - width % patch_size[1]) % patch_size[1]\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Patch the image\n",
    "    patches = []\n",
    "    for y in range(0, padded_image.shape[0], patch_size[0]):\n",
    "        for x in range(0, padded_image.shape[1], patch_size[1]):\n",
    "            patch = padded_image[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "            patches.append(patch / 255.0)  # Normalize\n",
    "\n",
    "    patches = np.array(patches)[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "    # Predict patches\n",
    "    predicted_patches = model.predict(patches)\n",
    "    predicted_patches = (predicted_patches > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Reconstruct the mask\n",
    "    reconstructed_mask = np.zeros_like(padded_image, dtype=np.uint8)\n",
    "    idx = 0\n",
    "    for y in range(0, padded_image.shape[0], patch_size[0]):\n",
    "        for x in range(0, padded_image.shape[1], patch_size[1]):\n",
    "            reconstructed_mask[y:y + patch_size[0], x:x + patch_size[1]] = predicted_patches[idx].squeeze()\n",
    "            idx += 1\n",
    "\n",
    "    # Crop back to the original size\n",
    "    return reconstructed_mask[:height, :width]\n",
    "\n",
    "\n",
    "def detect_root_tip_from_skeleton(mask):\n",
    "    \"\"\"\n",
    "    Detect the root tip (lowest point) in the skeletonized mask.\n",
    "\n",
    "    Parameters:\n",
    "    - mask: Binary mask (numpy array).\n",
    "\n",
    "    Returns:\n",
    "    - root_tip: Tuple (y_pixel, x_pixel) of the root tip.\n",
    "    \"\"\"\n",
    "    # Skeletonize the mask\n",
    "    skeleton = skeletonize(mask // 255)\n",
    "\n",
    "    # Find the lowest non-zero pixel in the skeleton\n",
    "    skeleton_pixels = np.argwhere(skeleton > 0)\n",
    "    if skeleton_pixels.size == 0:\n",
    "        raise ValueError(\"No root tip detected in skeleton.\")\n",
    "\n",
    "    root_tip = skeleton_pixels[np.argmax(skeleton_pixels[:, 0])]  # Lowest point (max y-coordinate)\n",
    "    return tuple(root_tip)\n",
    "\n",
    "\n",
    "def convert_pixel_to_mm(root_tip_pixel, image_height, plate_height_mm):\n",
    "    \"\"\"\n",
    "    Convert pixel coordinates to millimeters.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tip_pixel: Root tip coordinates in pixels (y_pixel, x_pixel).\n",
    "    - image_height: Height of the original image in pixels.\n",
    "    - plate_height_mm: Real-world height of the plate in millimeters.\n",
    "\n",
    "    Returns:\n",
    "    - root_tip_mm: Root tip coordinates in millimeters (x_mm, y_mm, z_mm).\n",
    "    \"\"\"\n",
    "    scale = plate_height_mm / image_height  # mm per pixel\n",
    "    y_mm = root_tip_pixel[0] * scale\n",
    "    x_mm = root_tip_pixel[1] * scale\n",
    "    return (x_mm, y_mm, 0)  # Assuming z=0 for simplicity\n",
    "\n",
    "\n",
    "def convert_to_robot_coordinates(root_tip_mm, plate_position_robot):\n",
    "    \"\"\"\n",
    "    Convert root tip positions in mm (relative to the plate) to robot space.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tip_mm: Root tip position in mm (x_mm, y_mm, z_mm).\n",
    "    - plate_position_robot: Position of the top-left corner of the plate in robot space [x, y, z].\n",
    "\n",
    "    Returns:\n",
    "    - root_tip_robot: Root tip position in robot space (x_robot, y_robot, z_robot).\n",
    "    \"\"\"\n",
    "    return [\n",
    "        root_tip_mm[0] + plate_position_robot[0],\n",
    "        root_tip_mm[1] + plate_position_robot[1],\n",
    "        root_tip_mm[2] + plate_position_robot[2],\n",
    "    ]\n",
    "\n",
    "\n",
    "def inoculate_with_pid(env, root_tips_robot):\n",
    "    \"\"\"\n",
    "    Perform root tip inoculation using the PID controller.\n",
    "\n",
    "    Parameters:\n",
    "    - env: The simulation environment.\n",
    "    - root_tips_robot: List of root tip coordinates in robot space [(x, y, z), ...].\n",
    "    \"\"\"\n",
    "    # Initialize PID controllers for X, Y, Z axes\n",
    "    pid_x = PIDController(kp=1.0, ki=0.1, kd=0.01)\n",
    "    pid_y = PIDController(kp=1.0, ki=0.1, kd=0.01)\n",
    "    pid_z = PIDController(kp=1.0, ki=0.1, kd=0.01)\n",
    "\n",
    "    for root_tip in root_tips_robot:\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        target_position = np.array(root_tip)\n",
    "\n",
    "        while not (terminated or truncated):\n",
    "            current_position = np.array(env.get_current_position())  # Robot's current position\n",
    "\n",
    "            # Compute errors\n",
    "            error_x = target_position[0] - current_position[0]\n",
    "            error_y = target_position[1] - current_position[1]\n",
    "            error_z = target_position[2] - current_position[2]\n",
    "\n",
    "            # PID outputs\n",
    "            control_x = pid_x.compute(error_x)\n",
    "            control_y = pid_y.compute(error_y)\n",
    "            control_z = pid_z.compute(error_z)\n",
    "\n",
    "            # Take action\n",
    "            action = np.array([control_x, control_y, control_z], dtype=np.float32)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # Check if the robot is within the acceptable error threshold\n",
    "            if np.linalg.norm(target_position - current_position) < 0.01:  # Example threshold\n",
    "                print(f\"Inoculating at {target_position}\")\n",
    "                env.drop_inoculum()  # Perform inoculation\n",
    "                break\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    model_path =r\"C:\\Users\\Edopi\\Desktop\\2024-25b-fai2-adsai-EdoardoPierezza231412\\datalab_tasks\\Task8\\Edoardo_231412_undet_model256px_base.h5\"\n",
    "    patch_size = (256, 256)\n",
    "    plate_position_robot = [0.10775, 0.088 - 0.026, 0.057]  # Adjusted plate position\n",
    "    image_height = 2816  # Original image height in pixels\n",
    "    plate_height_mm = 150  # Plate height in millimeters\n",
    "\n",
    "    # Initialize the environment\n",
    "    env = OT2Env()\n",
    "\n",
    "    # Capture the image\n",
    "    image_path = env.image()\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Crop the Petri dish\n",
    "    cropped_image, bbox, success = crop_petri_dish(image, patch_size)\n",
    "    if not success:\n",
    "        raise RuntimeError(\"Failed to detect and crop the Petri dish.\")\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path, custom_objects={\"f1\": f1, \"dice_loss\": dice_loss})\n",
    "\n",
    "    # Generate the mask\n",
    "    mask = generate_mask(cropped_image, model, patch_size)\n",
    "\n",
    "    # Detect the root tip\n",
    "    root_tip_pixel = detect_root_tip_from_skeleton(mask)\n",
    "\n",
    "    # Convert to mm\n",
    "    root_tip_mm = convert_pixel_to_mm(root_tip_pixel, image_height, plate_height_mm)\n",
    "\n",
    "    # Convert to robot coordinates\n",
    "    root_tip_robot = convert_to_robot_coordinates(root_tip_mm, plate_position_robot)\n",
    "\n",
    "    # Use the PID controller for inoculation\n",
    "    inoculate_with_pid(env, [root_tip_robot])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_mask(image, model, patch_size):\n",
    "    \"\"\"\n",
    "    Generate a mask from an image using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - model: Trained Keras model.\n",
    "    - patch_size: Tuple (height, width) for patching.\n",
    "\n",
    "    Returns:\n",
    "    - mask: Predicted binary mask (numpy array).\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    # Pad the image\n",
    "    pad_height = (patch_size[0] - height % patch_size[0]) % patch_size[0]\n",
    "    pad_width = (patch_size[1] - width % patch_size[1]) % patch_size[1]\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Patch the image\n",
    "    patches = []\n",
    "    for y in range(0, padded_image.shape[0], patch_size[0]):\n",
    "        for x in range(0, padded_image.shape[1], patch_size[1]):\n",
    "            patch = padded_image[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "            patches.append(patch / 255.0)  # Normalize\n",
    "\n",
    "    patches = np.array(patches)[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "    # Predict patches\n",
    "    predicted_patches = model.predict(patches)\n",
    "    predicted_patches = (predicted_patches > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Reconstruct the mask\n",
    "    reconstructed_mask = np.zeros_like(padded_image, dtype=np.uint8)\n",
    "    idx = 0\n",
    "    for y in range(0, padded_image.shape[0], patch_size[0]):\n",
    "        for x in range(0, padded_image.shape[1], patch_size[1]):\n",
    "            reconstructed_mask[y:y + patch_size[0], x:x + patch_size[1]] = predicted_patches[idx].squeeze()\n",
    "            idx += 1\n",
    "\n",
    "    # Crop back to the original size\n",
    "    return reconstructed_mask[:height, :width]\n",
    "\n",
    "def detect_root_tip_from_skeleton(mask):\n",
    "    \"\"\"\n",
    "    Detect the root tip (lowest point) in the skeletonized mask.\n",
    "\n",
    "    Parameters:\n",
    "    - mask: Binary mask (numpy array).\n",
    "\n",
    "    Returns:\n",
    "    - root_tip: Tuple (y_pixel, x_pixel) of the root tip.\n",
    "    \"\"\"\n",
    "    # Skeletonize the mask\n",
    "    skeleton = skeletonize(mask // 255)\n",
    "\n",
    "    # Find the lowest non-zero pixel in the skeleton\n",
    "    skeleton_pixels = np.argwhere(skeleton > 0)\n",
    "    if skeleton_pixels.size == 0:\n",
    "        raise ValueError(\"No root tip detected in skeleton.\")\n",
    "\n",
    "    root_tip = skeleton_pixels[np.argmax(skeleton_pixels[:, 0])]  # Lowest point (max y-coordinate)\n",
    "    return tuple(root_tip)\n",
    "\n",
    "def convert_pixel_to_mm(root_tip_pixel, image_height, plate_height_mm):\n",
    "    \"\"\"\n",
    "    Convert pixel coordinates to millimeters.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tip_pixel: Root tip coordinates in pixels (y_pixel, x_pixel).\n",
    "    - image_height: Height of the original image in pixels.\n",
    "    - plate_height_mm: Real-world height of the plate in millimeters.\n",
    "\n",
    "    Returns:\n",
    "    - root_tip_mm: Root tip coordinates in millimeters (x_mm, y_mm, z_mm).\n",
    "    \"\"\"\n",
    "    scale = plate_height_mm / image_height  # mm per pixel\n",
    "    y_mm = root_tip_pixel[0] * scale\n",
    "    x_mm = root_tip_pixel[1] * scale\n",
    "    return (x_mm, y_mm, 0)  # Assuming z=0 for simplicity\n",
    "\n",
    "def convert_to_robot_coordinates(root_tip_mm, plate_position_robot):\n",
    "    \"\"\"\n",
    "    Convert root tip positions in mm (relative to the plate) to robot space.\n",
    "\n",
    "    Parameters:\n",
    "    - root_tip_mm: Root tip position in mm (x_mm, y_mm, z_mm).\n",
    "    - plate_position_robot: Position of the top-left corner of the plate in robot space [x, y, z].\n",
    "\n",
    "    Returns:\n",
    "    - root_tip_robot: Root tip position in robot space (x_robot, y_robot, z_robot).\n",
    "    \"\"\"\n",
    "    return [\n",
    "        root_tip_mm[0] + plate_position_robot[0],\n",
    "        root_tip_mm[1] + plate_position_robot[1],\n",
    "        root_tip_mm[2] + plate_position_robot[2],\n",
    "    ]\n",
    "\n",
    "def inoculate_with_pid(env, root_tips_robot):\n",
    "    \"\"\"\n",
    "    Perform root tip inoculation using the PID controller.\n",
    "\n",
    "    Parameters:\n",
    "    - env: The simulation environment.\n",
    "    - root_tips_robot: List of root tip coordinates in robot space [(x, y, z), ...].\n",
    "    \"\"\"\n",
    "    # Initialize PID controllers for X, Y, Z axes\n",
    "    pid_x = PIDController(kp=1.0, ki=0.1, kd=0.01)\n",
    "    pid_y = PIDController(kp=1.0, ki=0.1, kd=0.01)\n",
    "    pid_z = PIDController(kp=1.0, ki=0.1, kd=0.01)\n",
    "\n",
    "    for root_tip in root_tips_robot:\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        target_position = np.array(root_tip)\n",
    "\n",
    "        while not (terminated or truncated):\n",
    "            current_position = np.array(env.get_current_position())  # Robot's current position\n",
    "\n",
    "            # Compute errors\n",
    "            error_x = target_position[0] - current_position[0]\n",
    "            error_y = target_position[1] - current_position[1]\n",
    "            error_z = target_position[2] - current_position[2]\n",
    "\n",
    "            # PID outputs\n",
    "            control_x = pid_x.compute(error_x)\n",
    "            control_y = pid_y.compute(error_y)\n",
    "            control_z = pid_z.compute(error_z)\n",
    "\n",
    "            # Take action\n",
    "            action = np.array([control_x, control_y, control_z], dtype=np.float32)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # Check if the robot is within the acceptable error threshold\n",
    "            if np.linalg.norm(target_position - current_position) < 0.01:  # Example threshold\n",
    "                print(f\"Inoculating at {target_position}\")\n",
    "                env.drop_inoculum()  # Perform inoculation\n",
    "                break\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    model_path = \"path_to_your_trained_model.h5\"\n",
    "    patch_size = (256, 256)\n",
    "    plate_position_robot = [0.10775, 0.088 - 0.026, 0.057]  # Adjusted plate position\n",
    "    image_height = 2816  # Original image height in pixels\n",
    "    plate_height_mm = 150  # Plate height in millimeters\n",
    "\n",
    "    # Initialize the simulation environment\n",
    "    env = RobotEnv()\n",
    "\n",
    "    # Get the image from the simulation\n",
    "    image = env.get_plate_image()\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Generate the mask\n",
    "    mask = generate_mask(image, model, patch_size)\n",
    "\n",
    "    # Detect the root tip\n",
    "    root_tip_pixel = detect_root_tip_from_skeleton(mask)\n",
    "\n",
    "    # Convert to mm\n",
    "    root_tip_mm = convert_pixel_to_mm(root_tip_pixel, image_height, plate_height_mm)\n",
    "\n",
    "    # Convert to robot coordinates\n",
    "    root_tip_robot = convert_to_robot_coordinates(root_tip_mm, plate_position_robot)\n",
    "\n",
    "    # Use the PID controller for inoculation\n",
    "    inoculate_with_pid(env, [root_tip_robot])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlockBR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
